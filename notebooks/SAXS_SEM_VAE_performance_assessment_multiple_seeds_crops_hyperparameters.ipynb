{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZTPRMnp4un7ihmv5WpmEazNXa7ycakWY","timestamp":1680889603292}],"collapsed_sections":["3BtvzFVxcbP0","uIyXenrEEJCr"],"machine_shape":"hm","authorship_tag":"ABX9TyNZe0duKpf5YYWXuLlSip9X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# module imports and data preprocessing"],"metadata":{"id":"3-eEX88ELTcN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFJt28Z_Kj_T","executionInfo":{"status":"ok","timestamp":1681043164840,"user_tz":240,"elapsed":19079,"user":{"displayName":"shizhao lu","userId":"06144541777385225680"}},"outputId":"bd62e797-bcc0-46cb-a0c0-8729d1515625"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["! pip install tensorflow==2.11.1\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","# tensorflow version used at development was 2.11.1, tf_io version: 0.31.0, tfp version: 0.19.0\n","# tensorflow on google colab upgraded to 2.12.0 at March 30. 2023, in middle of this project\n","# which introduced some compatibility issues, fixing the version at 2.11.1 have no issues.\n","\n","import torch\n","print(torch.__version__)\n","import matplotlib\n","print(matplotlib.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iGHMZ5RyKuin","executionInfo":{"status":"ok","timestamp":1681043247721,"user_tz":240,"elapsed":80625,"user":{"displayName":"shizhao lu","userId":"06144541777385225680"}},"outputId":"0d393bdd-3e79-4bb2-b45e-b0de2f1dfe8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.11.1\n","  Downloading tensorflow-2.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (1.14.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (23.0)\n","Collecting protobuf<3.20,>=3.9.2\n","  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (1.16.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (4.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (67.6.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (3.8.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (16.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (3.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (1.6.3)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (1.22.4)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (1.53.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (1.4.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (23.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (2.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (0.32.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.1) (0.4.0)\n","Collecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.1) (0.40.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (3.4.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.27.1)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.2.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.17.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (1.8.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (6.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (3.2.2)\n","Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.0\n","    Uninstalling tensorboard-data-server-0.7.0:\n","      Successfully uninstalled tensorboard-data-server-0.7.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.1\n","    Uninstalling tensorboard-2.12.1:\n","      Successfully uninstalled tensorboard-2.12.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","Successfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.1 tensorflow-estimator-2.11.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2.11.1\n","2.0.0+cu118\n","3.7.1\n"]}]},{"cell_type":"code","source":["# Other imports\n","! pip install tensorflow_addons==0.19.0\n","! pip install tensorflow_io==0.31.0\n","! pip install tensorflow_probability==0.19.0\n","! pip install porespy==2.2.2\n","\n","import os\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing.image import load_img\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n","from matplotlib.ticker import MultipleLocator, FormatStrFormatter, AutoMinorLocator\n","from imutils import paths\n","from tqdm import tqdm\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","# import tensorflow_datasets as tfds\n","import tensorflow_io as tfio\n","import tensorflow_hub as hub\n","import tensorflow_probability as tfp\n","\n","import numpy as np\n","import cv2\n","import pandas as pd\n","import seaborn as sns\n","from scipy import interpolate\n","from scipy.stats import wasserstein_distance\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.cluster import KMeans\n","from sklearn.manifold import TSNE\n","from sklearn.metrics.pairwise import cosine_similarity as cos\n","from sympy.utilities.iterables import multiset_permutations\n","from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score, roc_auc_score, confusion_matrix, mean_absolute_error\n","from sklearn.model_selection import *\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KernelDensity as kde\n","from IPython.display import Image, display\n","import porespy\n","from edt import edt\n","\n","tfpl = tfp.layers\n","tfd = tfp.distributions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3AV-va4KxmO","executionInfo":{"status":"ok","timestamp":1681043313635,"user_tz":240,"elapsed":65790,"user":{"displayName":"shizhao lu","userId":"06144541777385225680"}},"outputId":"637ea8d0-c10a-4fa6-9b84-671023d42226"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons==0.19.0\n","  Downloading tensorflow_addons-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typeguard>=2.7\n","  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow_addons==0.19.0) (23.0)\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow_addons==0.19.0) (6.1.0)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow_addons==0.19.0) (4.5.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.7->tensorflow_addons==0.19.0) (3.15.0)\n","Installing collected packages: typeguard, tensorflow_addons\n","Successfully installed tensorflow_addons-0.19.0 typeguard-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_io==0.31.0\n","  Downloading tensorflow_io-0.31.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.31.0\n","  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow_io\n","  Attempting uninstall: tensorflow-io-gcs-filesystem\n","    Found existing installation: tensorflow-io-gcs-filesystem 0.32.0\n","    Uninstalling tensorflow-io-gcs-filesystem-0.32.0:\n","      Successfully uninstalled tensorflow-io-gcs-filesystem-0.32.0\n","Successfully installed tensorflow-io-gcs-filesystem-0.31.0 tensorflow_io-0.31.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow_probability==0.19.0 in /usr/local/lib/python3.9/dist-packages (0.19.0)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.19.0) (2.2.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.19.0) (4.4.2)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.19.0) (1.22.4)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.19.0) (0.1.8)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.19.0) (1.16.0)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.19.0) (0.4.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from tensorflow_probability==0.19.0) (1.4.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting porespy==2.2.2\n","  Downloading porespy-2.2.2-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (2.25.1)\n","Requirement already satisfied: dask in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (2022.12.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (1.4.4)\n","Collecting scikit-fmm\n","  Downloading scikit-fmm-2023.4.2.tar.gz (435 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.1/435.1 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (1.10.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (0.19.3)\n","Collecting trimesh\n","  Downloading trimesh-3.21.4-py3-none-any.whl (680 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 KB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (13.3.3)\n","Collecting numpy-stl\n","  Downloading numpy_stl-3.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (1.22.4)\n","Collecting deprecated\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Collecting edt\n","  Downloading edt-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (0.56.4)\n","Collecting pyfastnoisesimd\n","  Downloading pyfastnoisesimd-0.4.2-cp39-cp39-manylinux2010_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyevtk\n","  Downloading pyevtk-1.5.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (4.65.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (3.7.1)\n","Collecting openpnm\n","  Downloading openpnm-3.1.2-py3-none-any.whl (299 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.1/299.1 KB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from porespy==2.2.2) (5.9.4)\n","Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from dask->porespy==2.2.2) (2023.3.0)\n","Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from dask->porespy==2.2.2) (2.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from dask->porespy==2.2.2) (6.0)\n","Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.9/dist-packages (from dask->porespy==2.2.2) (0.12.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from dask->porespy==2.2.2) (8.1.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from dask->porespy==2.2.2) (23.0)\n","Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.9/dist-packages (from dask->porespy==2.2.2) (1.3.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from deprecated->porespy==2.2.2) (1.14.1)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.9/dist-packages (from imageio->porespy==2.2.2) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->porespy==2.2.2) (3.0.9)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->porespy==2.2.2) (5.12.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->porespy==2.2.2) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->porespy==2.2.2) (4.39.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->porespy==2.2.2) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->porespy==2.2.2) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->porespy==2.2.2) (0.11.0)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->porespy==2.2.2) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->porespy==2.2.2) (67.6.1)\n","Requirement already satisfied: python-utils>=3.4.5 in /usr/local/lib/python3.9/dist-packages (from numpy-stl->porespy==2.2.2) (3.5.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from openpnm->porespy==2.2.2) (3.0)\n","Collecting docrep\n","  Downloading docrep-0.3.2.tar.gz (33 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from openpnm->porespy==2.2.2) (3.8.0)\n","Collecting chemicals\n","  Downloading chemicals-1.1.2-py3-none-any.whl (23.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transforms3d\n","  Downloading transforms3d-0.4.1.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from openpnm->porespy==2.2.2) (4.3.3)\n","Collecting pypardiso\n","  Downloading pypardiso-0.4.2-py3-none-any.whl (10 kB)\n","Collecting thermo\n","  Downloading thermo-0.2.23-py3-none-any.whl (8.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from openpnm->porespy==2.2.2) (1.11.1)\n","Collecting pyamg\n","  Downloading pyamg-4.2.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->porespy==2.2.2) (2022.7.1)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->porespy==2.2.2) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->porespy==2.2.2) (2.14.0)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->porespy==2.2.2) (1.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->porespy==2.2.2) (2023.3.21)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->porespy==2.2.2) (3.15.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->porespy==2.2.2) (0.1.2)\n","Requirement already satisfied: locket in /usr/local/lib/python3.9/dist-packages (from partd>=0.3.10->dask->porespy==2.2.2) (1.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->porespy==2.2.2) (1.16.0)\n","Collecting fluids>=1.0.21\n","  Downloading fluids-1.0.22-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->openpnm->porespy==2.2.2) (0.19.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->openpnm->porespy==2.2.2) (22.2.0)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.9/dist-packages (from pypardiso->openpnm->porespy==2.2.2) (2019.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->openpnm->porespy==2.2.2) (1.3.0)\n","Requirement already satisfied: intel-openmp in /usr/local/lib/python3.9/dist-packages (from mkl->pypardiso->openpnm->porespy==2.2.2) (2023.1.0)\n","Building wheels for collected packages: scikit-fmm, docrep, transforms3d\n","  Building wheel for scikit-fmm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-fmm: filename=scikit_fmm-2023.4.2-cp39-cp39-linux_x86_64.whl size=272845 sha256=3c3f872e0d49212d801f12419cab79cb9488c512b312062ec82cf5da94adc86b\n","  Stored in directory: /root/.cache/pip/wheels/00/a5/36/e735aaedca79d1b411c4d28235b570b5b77cc111a67714e0fd\n","  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docrep: filename=docrep-0.3.2-py3-none-any.whl size=19891 sha256=6cfde00575fcfac2a23e5f199fb9407b003662cd450323c2242a2d17b07f525b\n","  Stored in directory: /root/.cache/pip/wheels/e5/f0/3f/17394a03ed36922f620186a5a9ebd6bce2b4579020243c7a68\n","  Building wheel for transforms3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transforms3d: filename=transforms3d-0.4.1-py3-none-any.whl size=1376772 sha256=63f2441acba21207f9d64e2180fa14397cd06df97954815442deaa4f416de9fc\n","  Stored in directory: /root/.cache/pip/wheels/a5/2d/e4/5d7de7a69ab4e6301b3125441725d47fe25b9e60e7d670ad21\n","Successfully built scikit-fmm docrep transforms3d\n","Installing collected packages: trimesh, transforms3d, scikit-fmm, pyfastnoisesimd, pyevtk, numpy-stl, edt, docrep, deprecated, pypardiso, pyamg, fluids, chemicals, thermo, openpnm, porespy\n","Successfully installed chemicals-1.1.2 deprecated-1.2.13 docrep-0.3.2 edt-2.3.0 fluids-1.0.22 numpy-stl-3.0.1 openpnm-3.1.2 porespy-2.2.2 pyamg-4.2.3 pyevtk-1.5.0 pyfastnoisesimd-0.4.2 pypardiso-0.4.2 scikit-fmm-2023.4.2 thermo-0.2.23 transforms3d-0.4.1 trimesh-3.21.4\n"]}]},{"cell_type":"markdown","source":["# Define model functions and image preprocessing functions"],"metadata":{"id":"QndQLp0KsJ1X"}},{"cell_type":"markdown","source":["## image preprocessing functions"],"metadata":{"id":"3BtvzFVxcbP0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2Br7PHcTnGU"},"outputs":[],"source":["# Image preprocessing utils\n","def parse_images_saxs(image_path):\n","    image_string = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image_string, channels=3)\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    image = tf.image.resize(image, size=[sem_imageSize, sem_imageSize])\n","\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkDQhBaweeQv"},"outputs":[],"source":["# Image preprocessing utils\n","def parse_images_saxs_for_mapping_tf_ds(image_path):\n","    image_string = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image_string, channels=3)\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    image = tf.image.resize(image, size=[sem_imageSize, sem_imageSize])\n","\n","    return image, image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbunDPw1Yk73"},"outputs":[],"source":["# Image preprocessing utils\n","def parse_images_sem_TSNE(image_path):\n","    image_string = tf.io.read_file(image_path)\n","    image = tfio.experimental.image.decode_tiff(image_string)[:, :, :3]   # in the doc, it transforms tiff to 4 channels, with additional channel of opacity which is not needed.\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    image = image[:sem_original_x_length, :sem_original_y_length, :]\n","    image = image[:sem_imageSize, :sem_imageSize, :]\n","\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08nQfUMNe1OI"},"outputs":[],"source":["# Image preprocessing utils\n","def parse_images_sem_no_crop(image_path):\n","    image_string = tf.io.read_file(image_path)\n","    image = tfio.experimental.image.decode_tiff(image_string)[:, :, :3]   # in the doc, it transforms tiff to 4 channels, with additional channel of opacity which is not needed.\n","    image = image[:sem_original_x_length, :sem_original_y_length, :]\n","    image = tfa.image.gaussian_filter2d(image, 5)\n","    image = cv2.cvtColor(image.numpy().astype('float32'), cv2.COLOR_BGR2GRAY)\n","    image = cv2.adaptiveThreshold(image.astype('uint8'), 1, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, adapt_window, 2)\n","    image = cv2.GaussianBlur(image,(5,5),0)\n","\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPuFeamLVN2f"},"outputs":[],"source":["# Image preprocessing utils\n","def parse_images_sem_crop(image_path, left, bottom):\n","    image_string = tf.io.read_file(image_path)\n","    image = tfio.experimental.image.decode_tiff(image_string)[:, :, :3]   # in the doc, it transforms tiff to 4 channels, with additional channel of opacity which is not needed.\n","    image = image[:sem_original_x_length, :sem_original_y_length, :]\n","    image = tfa.image.gaussian_filter2d(image, 5)\n","    image = cv2.cvtColor(image.numpy().astype('float32'), cv2.COLOR_BGR2GRAY)\n","    image = cv2.adaptiveThreshold(image.astype('uint8'), 1, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, adapt_window, 2)\n","    image = cv2.GaussianBlur(image,(5,5),0)\n","    image = image[left:left+sem_imageSize, bottom:bottom+sem_imageSize]\n","\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSyUX5kKULB9"},"outputs":[],"source":["# Image preprocessing utils\n","def parse_images_sem_crop_tf_ds(image, left, bottom):\n","    # left = 0\n","    # bottom = 0\n","    image = image[left:left+sem_imageSize, bottom:bottom+sem_imageSize, :]\n","    image_2d = image[:, :, 0]\n","\n","    return image, image_2d"]},{"cell_type":"markdown","metadata":{"id":"uIyXenrEEJCr"},"source":["## functions for vae model building"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681043313637,"user":{"displayName":"shizhao lu","userId":"06144541777385225680"},"user_tz":240},"id":"CM3MP_d2DscS","outputId":"920c463e-b33d-4ec1-ae6b-73694aba690c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1qb_BrPe6oJ2Dg0E6xoFYETWtLHETrwQj/nanowire-morphology-classification-project\n"]}],"source":["%cd \"/content/drive/MyDrive/nanowire-morphology-classification-project\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LStJ1VzRD-U5"},"outputs":[],"source":["def upsample(filters, size, apply_dropout=False):\n","\n","  result = Sequential()\n","  result.add(\n","    Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer='he_normal',\n","                                    bias_initializer='he_normal'))\n","\n","  result.add(BatchNormalization())\n","\n","  if apply_dropout:\n","      result.add(Dropout(0.5))\n","\n","  result.add(ReLU())\n","\n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EjEAeJgKELE9"},"outputs":[],"source":["# define loss functions and metrics for segmentation task\n","# coef functions are for batches of images, score functions are for a single image\n","\n","def dice_coef_2d(y_true, y_pred, smooth=0.000001):\n","  \n","    beta = 1\n","    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2])\n","    fp = tf.reduce_sum(y_pred, axis=[1,2]) - tp\n","    fn = tf.reduce_sum(y_true, axis=[1,2]) - tp\n","\n","    score = tf.reduce_mean(((1 + beta ** 2) * tp + smooth) \\\n","            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth))\n","    return score\n","\n","def dice_coef_3d(y_true, y_pred, smooth=0.000001):\n","  \n","    beta = 1\n","    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n","    fp = tf.reduce_sum(y_pred, axis=[1,2,3]) - tp\n","    fn = tf.reduce_sum(y_true, axis=[1,2,3]) - tp\n","\n","    score = tf.reduce_mean(((1 + beta ** 2) * tp + smooth) \\\n","            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth))\n","    return score\n","\n","def dice_score(y_true, y_pred, smooth=0.000001):\n","  y_true = y_true.astype('float32')\n","  y_pred = y_pred.astype('float32')\n","  beta = 1\n","  tp = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n","  fp = tf.reduce_sum(y_pred, axis=[1, 2]) - tp\n","  fn = tf.reduce_sum(y_true, axis=[1, 2]) - tp\n","\n","  score = tf.reduce_mean(((1 + beta ** 2) * tp + smooth) \\\n","          / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth)).numpy()\n","  return score\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1 - dice_coef(y_true, y_pred)\n","\n","def iou_coef(y_true, y_pred, smooth=0.000001):\n","\n","    beta = 1\n","    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2])\n","    fp = tf.reduce_sum(y_pred, axis=[1,2]) - tp\n","    fn = tf.reduce_sum(y_true, axis=[1,2]) - tp\n","\n","    score = tf.reduce_mean((tp + smooth) \\\n","            / (tp + fn + fp + smooth))\n","    return score\n","\n","def iou_score(y_true, y_pred, smooth=0.000001):\n","  y_true = y_true.astype('float32')\n","  tp = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n","  fp = tf.reduce_sum(y_pred, axis=[1, 2]) - tp\n","  fn = tf.reduce_sum(y_true, axis=[1, 2]) - tp\n","\n","  score = tf.reduce_mean((tp + smooth) \\\n","          / (tp + fn + fp + smooth)).numpy()\n","  return score\n","\n","def iou_coef_loss(y_true, y_pred):\n","    return 1 - iou_coef(y_true, y_pred)\n","\n","negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)\n","\n","def softmax_loss(y_true, y_pred):\n","  softmax_loss = tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred, axis=[1, 2, 3])\n","  return softmax_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CH5bSh0jENFb"},"outputs":[],"source":["def saxs_encoder(shape, feature_extractor_model, num_features, prior, kl_weight):\n","  inputs = Input(shape)\n","\n","  x = feature_extractor_model(inputs)\n","\n","  x = Dense(num_features, activation='relu', kernel_initializer='random_normal')(x)\n","  \n","  # x = AveragePooling2D((2,2))(x)\n","\n","  encoded_size = x.shape[-1]\n","  \n","  # options for distribution: IndependentNormal or MultivariateNormalTriL\n","  x = Dense(tfpl.IndependentNormal.params_size(encoded_size), activation=None)(x)\n","  x = tfpl.IndependentNormal(encoded_size, activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=kl_weight))(x)\n","  return Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRGwDCylEO9B"},"outputs":[],"source":["def saxs_decoder(shape, num_filter, filter_size):\n","  inputs = Input(shape)\n","\n","  x = inputs\n","\n","  upsampling_block = [\n","    upsample(num_filter, filter_size),\n","    upsample(num_filter, filter_size),\n","    upsample(num_filter, filter_size),\n","    upsample(num_filter, filter_size),\n","    # upsample(num_filter, filter_size),\n","  ]\n","\n","  # x = Reshape((1, 1, x.shape[-1]))(x)\n","\n","  for up in upsampling_block:\n","    x = up(x)\n","  \n","  last = Conv2DTranspose(3, filter_size,    # number of class, size of input vector (batch_size, x, y, class)\n","                              strides=2,\n","                              padding='same',\n","                              bias_initializer='he_normal',\n","                              kernel_initializer='he_normal',\n","                              activation='sigmoid')       # (batch_size, resolution, resolution, 3)\n","                              # sigmoid activation transforms values to between 0 and 1\n","  \n","  x = last(x)\n","  # Bernoulli distribution for the recreated image, for it's binary. () means we don't want the third dimension. We want (imageSize, imageSize)\n","  # x = tfpl.IndependentBernoulli((), convert_to_tensor_fn=tfd.Distribution.mode)(x)\n","\n","  return Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTdELKPt2O8C"},"outputs":[],"source":["def sem_encoder(shape, feature_extractor_model, num_features, prior, kl_weight):\n","  inputs = Input(shape)\n","\n","  x = feature_extractor_model(inputs)\n","\n","  x = Dense(num_features, activation='relu', kernel_initializer='random_normal')(x)\n","  \n","  # x = AveragePooling2D((2,2))(x)\n","\n","  encoded_size = x.shape[-1]\n","  \n","  # options for distribution: IndependentNormal or MultivariateNormalTriL\n","  x = Dense(tfpl.IndependentNormal.params_size(encoded_size), activation=None)(x)\n","  x = tfpl.IndependentNormal(encoded_size, activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=kl_weight))(x)\n","  return Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LBGSfucg2Riy"},"outputs":[],"source":["def sem_decoder(shape, num_filter, filter_size):\n","  inputs = Input(shape)\n","\n","  x = inputs\n","\n","  upsampling_block = [\n","    upsample(num_filter, filter_size),\n","    upsample(num_filter, filter_size),\n","    upsample(num_filter, filter_size),\n","    upsample(num_filter, filter_size),\n","    # upsample(num_filter, filter_size),\n","  ]\n","\n","  # x = Reshape((1, 1, x.shape[-1]))(x)\n","\n","  for up in upsampling_block:\n","    x = up(x)\n","  \n","  last = Conv2DTranspose(num_filter, filter_size,    # size of input vector (batch_size, x, y, num_filter)\n","                              strides=2,\n","                              padding='same',\n","                              bias_initializer='he_normal',\n","                              kernel_initializer='he_normal',\n","                              activation=None)\n","                              # no activation here because we are use logits directly in the Bernoulli layer, \n","                              # and the Bernoulli layer will act as an activation layer\n","  \n","  x = last(x)\n","  x = tf.reduce_mean(x, axis=-1, keepdims=True)\n","\n","  # Bernoulli distribution for the recreated image, for it's binary. () means we don't want the third dimension. We want (imageSize, imageSize)\n","  x = tfpl.IndependentBernoulli((), convert_to_tensor_fn=tfd.Distribution.mode)(x)\n","\n","  return Model(inputs=inputs, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQJfeSliEl7_"},"outputs":[],"source":["def get_pretrained_image_encoder_model(Resnet50_backbone, imagesize, hidden_1, hidden_2, hidden_3):\n","    base_model = Resnet50_backbone\n","    base_model.trainable = True\n","    inputs = Input((imagesize, imagesize, 3))\n","    h = base_model(inputs, training=True)\n","    h = GlobalAveragePooling2D()(h)\n","\n","    projection_1 = Dense(hidden_1)(h)                                        \n","    projection_1 = Activation(\"relu\")(projection_1)\n","    projection_1 = BatchNormalization(epsilon=0.001)(projection_1)\n","    projection_2 = Dense(hidden_2)(projection_1)\n","    projection_2 = Activation(\"relu\")(projection_2)\n","    projection_2 = BatchNormalization(epsilon=0.001)(projection_2)\n","    projection_3 = Dense(hidden_3)(projection_2)\n","    projection_3 = BatchNormalization(epsilon=0.001)(projection_3)\n","\n","    resnet_model = Model(inputs, projection_3)\n","    \n","    return resnet_model"]},{"cell_type":"markdown","source":["# hyperparameters"],"metadata":{"id":"4dITPn7Qd1dp"}},{"cell_type":"code","source":["training_batch_size = 8\n","\n","# cropped image size for both saxs and sem images\n","saxs_imageSize = 192\n","sem_imageSize = 192\n","\n","train_ratio = 6 / 9\n","\n","# size of the latent space for both autoencoders\n","latent_space_num_filters = 32\n","\n","# sem image without the bottom part\n","sem_original_x_length = 830\n","sem_original_y_length = 1280\n","\n","# window size for adaptive thresholding\n","adapt_window = 25\n","\n","# pair vae training hyperparameters\n","method = 'barlow'\n","\n","sim_weight = 5e-3\n","saxs_saxs_weight = 4e-2\n","saxs_sem_weight = 4e-1\n","sem_sem_weight = 4e-2\n","sem_saxs_weight = 1e0"],"metadata":{"id":"2egWMr-eGzwl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# initiate trained SAXS and SEM VAE model and load SAXS and SEM images"],"metadata":{"id":"H8CZyp2shcgF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mz3krCBqEgLf","executionInfo":{"status":"ok","timestamp":1681043322709,"user_tz":240,"elapsed":8847,"user":{"displayName":"shizhao lu","userId":"06144541777385225680"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c442b69c-b7ac-4507-d9ad-ab5d5425c1f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 1s 0us/step\n"]}],"source":["Resnet50_transfer_sem = tf.keras.applications.ResNet50(\n","    include_top=False,\n","    weights=None,\n","    input_tensor=None,\n","    input_shape=(sem_imageSize, sem_imageSize, 3), \n","    pooling=None,\n",")\n","\n","Resnet50_transfer_saxs = tf.keras.applications.ResNet50(\n","    include_top=False,\n","    weights=None,\n","    input_tensor=None,\n","    input_shape=(saxs_imageSize, saxs_imageSize, 3), \n","    pooling=None,\n",")\n","\n","Resnet50_transfer_sem.trainable = False\n","Resnet50_transfer_saxs.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"keXydNfspiXi"},"outputs":[],"source":["num_filter = 8\n","filter_size = 5\n","prior_mean = 0\n","prior_variance = 1\n","saxs_kl_weight = 1e-6\n","\n","encoder_res = np.array([512])\n","encoder_batch_size = np.array([8])\n","random_seed_list = np.array([45])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5521,"status":"ok","timestamp":1681043328228,"user":{"displayName":"shizhao lu","userId":"06144541777385225680"},"user_tz":240},"outputId":"09278f52-f1b9-43c8-8657-5786d5df0ec8","id":"KmNP6-dLpiXi"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=tfp.distributions._TensorCoercible(\"tensor_coercible\", batch_shape=[?, 6, 6], event_shape=[32], dtype=float32). Consider rewriting this model with the Functional API.\n"]}],"source":["# this is the training block of vae_encoder and vae_decoder\n","resnet_model = get_pretrained_image_encoder_model(Resnet50_transfer_saxs, saxs_imageSize, 128, 64, 1024)\n","if encoder_res[0] == 224:\n","  resnet_model.load_weights('barlow_resnet_batch%i_project128_64_1024_seed%i.h5' % (encoder_batch_size[0], random_seed_list[0]))\n","else:\n","  resnet_model.load_weights('barlow_resnet_batch%i_project128_64_1024_res%i_seed%i.h5' % (encoder_batch_size[0], encoder_res[0], random_seed_list[0]))\n","trained_resnet50 = resnet_model.get_layer('resnet50')\n","trained_resnet50.trainable = False\n","\n","saxs_encoded_size = [saxs_imageSize // 32, saxs_imageSize // 32, latent_space_num_filters]\n","\n","# gaussian distribution as the prior distribution for the encoded latent space\n","saxs_prior = tfd.Independent(tfd.Normal(loc=tf.zeros(saxs_encoded_size) + prior_mean, scale=prior_variance), reinterpreted_batch_ndims=1)\n","\n","vae_saxs_encoder = saxs_encoder((saxs_imageSize, saxs_imageSize, 3), trained_resnet50, latent_space_num_filters, saxs_prior, saxs_kl_weight)\n","\n","vae_saxs_decoder = saxs_decoder(saxs_encoded_size, num_filter, filter_size)\n","\n","saxs_vae = Model(inputs=vae_saxs_encoder.inputs, outputs=vae_saxs_decoder(vae_saxs_encoder.outputs[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLoQtNEVpiXi"},"outputs":[],"source":["num_filter = 32\n","filter_size = 15\n","prior_mean = 0\n","prior_variance = 1\n","sem_kl_weight = 1e-6\n","\n","encoder_res = np.array([512])\n","encoder_batch_size = np.array([8])\n","random_seed_list = np.array([45])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3142,"status":"ok","timestamp":1681043331368,"user":{"displayName":"shizhao lu","userId":"06144541777385225680"},"user_tz":240},"outputId":"a9cae5ab-18d3-47e6-998f-a7c39c498bba","id":"2RFXvnkOpiXj"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=tfp.distributions._TensorCoercible(\"tensor_coercible\", batch_shape=[?, 6, 6], event_shape=[32], dtype=float32). Consider rewriting this model with the Functional API.\n"]}],"source":["# this is the training block of vae_encoder and vae_decoder\n","resnet_model = get_pretrained_image_encoder_model(Resnet50_transfer_sem, sem_imageSize, 128, 64, 1024)\n","if encoder_res[0] == 224:\n","  resnet_model.load_weights('barlow_resnet_batch%i_project128_64_1024_seed%i.h5' % (encoder_batch_size[0], random_seed_list[0]))\n","else:\n","  resnet_model.load_weights('barlow_resnet_batch%i_project128_64_1024_res%i_seed%i.h5' % (encoder_batch_size[0], encoder_res[0], random_seed_list[0]))\n","trained_resnet50 = resnet_model.get_layer('resnet50')\n","trained_resnet50.trainable = False\n","\n","sem_encoded_size = [sem_imageSize // 32, sem_imageSize // 32, latent_space_num_filters]\n","\n","# gaussian distribution as the prior distribution for the encoded latent space\n","sem_prior = tfd.Independent(tfd.Normal(loc=tf.zeros(sem_encoded_size) + prior_mean, scale=prior_variance), reinterpreted_batch_ndims=1)\n","\n","vae_sem_encoder = sem_encoder((sem_imageSize, sem_imageSize, 3), trained_resnet50, latent_space_num_filters, sem_prior, sem_kl_weight)\n","\n","vae_sem_decoder = sem_decoder(sem_encoded_size, num_filter, filter_size)\n","\n","sem_vae = Model(inputs=vae_sem_encoder.inputs, outputs=vae_sem_decoder(vae_sem_encoder.outputs[0]))"]},{"cell_type":"code","source":["sem_image_path = \"/content/drive/MyDrive/TEM image datasets/2023-Sci-Adv-SAXS-SEM/SEM\"\n","sem_image_file_list = list(paths.list_files(basePath=sem_image_path, validExts='tif'))\n","sem_image_file_list.sort()\n","sem_image_file_list = np.array(sem_image_file_list)\n","saxs_image_path = \"/content/drive/MyDrive/TEM image datasets/2023-Sci-Adv-SAXS-SEM/SAXS\"\n","saxs_image_file_list = list(paths.list_files(basePath=saxs_image_path, validExts='jpg'))\n","saxs_image_file_list.sort()\n","saxs_image_file_list = np.array(saxs_image_file_list)\n","\n","sem_image_holder = np.zeros((len(sem_image_file_list), sem_imageSize, sem_imageSize, 3))\n","sem_image_2d_holder = np.zeros((len(sem_image_file_list), sem_imageSize, sem_imageSize))\n","saxs_image_holder = np.zeros((len(saxs_image_file_list), saxs_imageSize, saxs_imageSize, 3))\n","for i in range(len(saxs_image_file_list)):\n","        saxs_image_holder[i] = parse_images_saxs(saxs_image_file_list[i])"],"metadata":{"id":"GY00wMXuGuye"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Solo trained models performance assessment: 5 models trained with different selections of training images, and assessing with 10 random SEM crops."],"metadata":{"id":"FedIq_AIFGLz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqISAFIWDpHy"},"outputs":[],"source":["random_seed = np.linspace(42, 46, 5)\n","random_seed_for_crop = np.linspace(42, 51, 10).astype(int)\n","\n","sem_mean_average_error = np.zeros((len(random_seed), len(random_seed_for_crop), len(sem_image_file_list)))\n","saxs_mean_average_error = np.zeros((len(random_seed), len(sem_image_file_list)))\n","\n","# resolution = 192\n","x_two_point_corr = np.linspace(0.5, sem_image_2d_holder.shape[-1] / 2 - 0.5, int(sem_image_2d_holder.shape[-1] / 2))\n","\n","for k in range(len(random_seed)):\n","\n","  mother_directory = '/content/drive/MyDrive/ML projects/SAXS_SEM/solo_trained_models/'\n","  save_file_name = 'cropSize%i_windowSize%i_latentSize%i_trainSize%i_seed%i.h5' \\\n","  % (saxs_imageSize, adapt_window, latent_space_num_filters, np.rint(len(sem_image_file_list) * train_ratio).astype(int), random_seed[k])\n","\n","  vae_saxs_encoder.load_weights(mother_directory + 'saxs_encoder_' + save_file_name)\n","  vae_saxs_decoder.load_weights(mother_directory + 'saxs_decoder_' + save_file_name)\n","  vae_sem_encoder.load_weights(mother_directory + 'sem_encoder_' + save_file_name)\n","  vae_sem_decoder.load_weights(mother_directory + 'sem_decoder_' + save_file_name)\n","\n","  saxs_reconstruction = saxs_vae(saxs_image_holder)[:].numpy()\n","\n","  for m in range(sem_image_2d_holder.shape[0]):\n","    saxs_mean_average_error[k, m] = mean_absolute_error(np.reshape(saxs_reconstruction[m], (-1, 1)), np.reshape(saxs_image_holder[m], (-1, 1)))\n","\n","  for j in range(len(random_seed_for_crop)):\n","      np.random.seed(random_seed_for_crop[j])\n","      tf.random.set_seed(random_seed_for_crop[j])\n","\n","      rng = np.random.default_rng(seed=random_seed_for_crop[j])\n","      \n","      for i in range(len(sem_image_file_list)):\n","        sem_image_2d_holder[i] = parse_images_sem_crop(sem_image_file_list[i], rng.integers(0, sem_original_x_length - sem_imageSize), rng.integers(0, sem_original_y_length - sem_imageSize))\n","        sem_image_holder[i] = np.stack((sem_image_2d_holder[i], sem_image_2d_holder[i], sem_image_2d_holder[i]), axis=-1)\n","\n","      sem_reconstruction = sem_vae(sem_image_holder)[:].numpy()\n","\n","      # calculate 2-point correlation for true images\n","\n","      true_two_point_corr = np.zeros((sem_image_2d_holder.shape[0], len(x_two_point_corr)))\n","\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        image = sem_image_2d_holder[m]\n","        # vector metrics: 2-point correlation function\n","        true_two_point_corr[m, :] = porespy.metrics.two_point_correlation(image).pdf\n","        # .probability is the normalized where the 0th point is normalized to 1, .pdf is raw, where the 0th point is the porosity\n","        # check porespy.metrics.two_point_correlation(image).distance when mismatch error occurs\n","\n","      # calculate 2-point correlation for reconstructed images\n","\n","      gen_two_point_corr = np.zeros((sem_image_2d_holder.shape[0], len(x_two_point_corr)))\n","\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        image = sem_reconstruction[m]\n","        # vector metrics: 2-point correlation function\n","        gen_two_point_corr[m, :] = porespy.metrics.two_point_correlation(image).pdf\n","        # .probability is the normalized where the 0th point is normalized to 1, .pdf is raw, where the 0th point is the porosity\n","        # check porespy.metrics.two_point_correlation(image).distance when mismatch error occurs\n","\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        sem_mean_average_error[k, j, m] = mean_absolute_error(gen_two_point_corr[m], true_two_point_corr[m])\n","\n","mother_directory = '/content/drive/MyDrive/ML projects/SAXS_SEM/performance_assessment/'\n","save_file_name = 'cropSize%i_windowSize%i_latentSize%i_trainSize%i' \\\n","  % (saxs_imageSize, adapt_window, latent_space_num_filters, np.rint(len(sem_image_file_list) * train_ratio).astype(int))\n","np.savez_compressed(mother_directory + 'solo_vae_' + save_file_name + '.npz', saxs_mae=saxs_mean_average_error, sem_mae=sem_mean_average_error)"]},{"cell_type":"markdown","source":["# Pair trained models performance assessment: 5 models trained with different selections of training images, and assessing with 10 random SEM crops."],"metadata":{"id":"OMYFeo8g4Vrk"}},{"cell_type":"code","source":["random_seed = np.linspace(42, 46, 5)\n","random_seed_for_crop = np.linspace(42, 51, 10).astype(int)\n","\n","sem_sem_mean_average_error = np.zeros((len(random_seed), len(random_seed_for_crop), len(sem_image_file_list)))\n","saxs_sem_mean_average_error = np.zeros((len(random_seed), len(random_seed_for_crop), len(sem_image_file_list)))\n","saxs_saxs_mean_average_error = np.zeros((len(random_seed), len(sem_image_file_list)))\n","sem_saxs_mean_average_error = np.zeros((len(random_seed), len(random_seed_for_crop), len(sem_image_file_list)))\n","\n","# resolution = 192\n","x_two_point_corr = np.linspace(0.5, sem_image_2d_holder.shape[-1] / 2 - 0.5, int(sem_image_2d_holder.shape[-1] / 2))\n","\n","for k in range(len(random_seed)):\n","\n","  mother_directory = '/content/drive/MyDrive/ML projects/SAXS_SEM/pair_trained_models/'\n","  save_file_name = 'cropSize%i_windowSize%i_latentSize%i_trainSize%i_%s_%0.0e_%0.0e_%0.0e_%0.0e_%0.0e_seed%i.h5' \\\n","  % (sem_imageSize, adapt_window, latent_space_num_filters, np.rint(len(sem_image_file_list) * train_ratio).astype(int), method, sim_weight, saxs_saxs_weight, saxs_sem_weight, sem_sem_weight, sem_saxs_weight, random_seed[k])\n","\n","  vae_saxs_encoder.load_weights(mother_directory + 'saxs_encoder_' + save_file_name)\n","  vae_saxs_decoder.load_weights(mother_directory + 'saxs_decoder_' + save_file_name)\n","  vae_sem_encoder.load_weights(mother_directory + 'sem_encoder_' + save_file_name)\n","  vae_sem_decoder.load_weights(mother_directory + 'sem_decoder_' + save_file_name)\n","\n","  saxs_saxs_recon = saxs_vae(saxs_image_holder)[:].numpy()\n","\n","  for m in range(sem_image_2d_holder.shape[0]):\n","    saxs_saxs_mean_average_error[k, m] = mean_absolute_error(np.reshape(saxs_saxs_recon[m], (-1, 1)), np.reshape(saxs_image_holder[m], (-1, 1)))\n","\n","  for j in range(len(random_seed_for_crop)):\n","      np.random.seed(random_seed_for_crop[j])\n","      tf.random.set_seed(random_seed_for_crop[j])\n","\n","      rng = np.random.default_rng(seed=random_seed_for_crop[j])\n","      \n","      for i in range(len(sem_image_file_list)):\n","        sem_image_2d_holder[i] = parse_images_sem_crop(sem_image_file_list[i], rng.integers(0, sem_original_x_length - sem_imageSize), rng.integers(0, sem_original_y_length - sem_imageSize))\n","        sem_image_holder[i] = np.stack((sem_image_2d_holder[i], sem_image_2d_holder[i], sem_image_2d_holder[i]), axis=-1)\n","\n","      sem_sem_recon = sem_vae(sem_image_holder)[:].numpy()\n","\n","      # calculate 2-point correlation for true images\n","\n","      true_two_point_corr = np.zeros((sem_image_2d_holder.shape[0], len(x_two_point_corr)))\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        image = sem_image_2d_holder[m]\n","        true_two_point_corr[m, :] = porespy.metrics.two_point_correlation(image).pdf\n"," \n","      # calculate 2-point correlation for sem-sem reconstruction\n","\n","      sem_sem_two_point_corr = np.zeros((sem_image_2d_holder.shape[0], len(x_two_point_corr)))\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        image = sem_sem_recon[m]\n","        sem_sem_two_point_corr[m, :] = porespy.metrics.two_point_correlation(image).pdf\n","\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        sem_sem_mean_average_error[k, j, m] = mean_absolute_error(sem_sem_two_point_corr[m], true_two_point_corr[m])\n","      \n","      saxs_sem_recon = vae_sem_decoder(vae_saxs_encoder(saxs_image_holder))[:].numpy()\n","\n","      # calculate 2-point correlation for saxs-sem reconstruction\n","\n","      saxs_sem_two_point_corr = np.zeros((sem_image_2d_holder.shape[0], len(x_two_point_corr)))\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        image = saxs_sem_recon[m]\n","        saxs_sem_two_point_corr[m, :] = porespy.metrics.two_point_correlation(image).pdf\n","\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        saxs_sem_mean_average_error[k, j, m] = mean_absolute_error(saxs_sem_two_point_corr[m], true_two_point_corr[m])\n","\n","      # mean_absolute_error of sem to saxs reconstruction\n","      sem_saxs_recon = vae_saxs_decoder(vae_sem_encoder(sem_image_holder))[:].numpy()\n","\n","      for m in range(sem_image_2d_holder.shape[0]):\n","        sem_saxs_mean_average_error[k, j, m] = mean_absolute_error(np.reshape(sem_saxs_recon[m], (-1, 1)), np.reshape(saxs_image_holder[m], (-1, 1)))\n","\n","mother_directory = '/content/drive/MyDrive/ML projects/SAXS_SEM/performance_assessment/'\n","save_file_name = 'cropSize%i_windowSize%i_latentSize%i_trainSize%i' \\\n","  % (saxs_imageSize, adapt_window, latent_space_num_filters, np.rint(len(sem_image_file_list) * train_ratio).astype(int))\n","np.savez_compressed(mother_directory + 'pair_vae_' + save_file_name + '.npz', \\\n","                    saxs_saxs_mae=saxs_saxs_mean_average_error, sem_sem_mae=sem_sem_mean_average_error, saxs_sem_mae=saxs_sem_mean_average_error, sem_saxs_mae=sem_saxs_mean_average_error)"],"metadata":{"id":"LWPx3i2jriFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J03B9Kiu6_cB"},"execution_count":null,"outputs":[]}]}